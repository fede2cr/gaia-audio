# ── Build stage ─────────────────────────────────────────────────────
FROM debian:trixie AS builder

RUN apt-get update && apt-get install -y --no-install-recommends \
    curl ca-certificates \
    pkg-config libssl-dev \
    gcc libc6-dev \
    && rm -rf /var/lib/apt/lists/*

ENV RUSTUP_HOME=/usr/local/rustup CARGO_HOME=/usr/local/cargo
ENV PATH="/usr/local/cargo/bin:$PATH"
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y --default-toolchain stable

WORKDIR /build

# Copy workspace manifests first for dependency caching
COPY Cargo.toml Cargo.lock ./
COPY common/Cargo.toml common/Cargo.toml
COPY capture/Cargo.toml capture/Cargo.toml
COPY processing/Cargo.toml processing/Cargo.toml
COPY web/Cargo.toml web/Cargo.toml

# Create dummy sources so cargo can fetch/compile dependencies
RUN mkdir -p common/src capture/src processing/src web/src && \
    echo "pub fn _dummy() {}" > common/src/lib.rs && \
    echo "fn main() {}" > capture/src/main.rs && \
    echo "fn main() {}" > processing/src/main.rs && \
    echo "pub fn _dummy() {}" > web/src/lib.rs && \
    echo "fn main() {}" > web/src/main.rs && \
    cargo build --release -p gaia-processing 2>/dev/null || true

# Copy real source (touch to invalidate cargo fingerprint from dummy layer)
COPY common/src common/src
COPY processing/src processing/src
RUN touch common/src/lib.rs processing/src/main.rs

# Build for real
RUN cargo build --release -p gaia-processing

# ── Keras → ONNX conversion at build time ─────────────────────────
# Downloads the BirdNET V2.4 Keras model from Zenodo, splits at the
# concatenate layer (removing the RFFT-based mel-spectrogram layers),
# and converts only the CNN classifier to ONNX.
#
# The resulting ~49 MB ONNX file is baked into the image.  No Python
# or TensorFlow is needed at runtime — the mel-spectrogram
# preprocessing runs in native Rust (mel.rs).
# Use Python 3.11 + TF 2.15 (last release with built-in Keras 2).
# TF 2.16+ split Keras out to tf_keras, which has deserialization bugs
# with BirdNET V2.4's MelSpecLayerSimple functional graph.
FROM python:3.11-slim AS converter

RUN pip install --no-cache-dir 'pycparser<3' && \
    pip install --no-cache-dir 'tensorflow==2.15.*' tf2onnx onnxruntime

WORKDIR /convert
COPY scripts/convert_keras_to_onnx.py .

# Download Keras zip from Zenodo and extract (flatten directory structure).
# python:3.12-slim does not include curl, so we use urllib instead.
RUN python3 -c "\
import urllib.request, zipfile, os, shutil; \
print('Downloading BirdNET V2.4 Keras model from Zenodo...'); \
urllib.request.urlretrieve( \
    'https://zenodo.org/api/records/15050749/files/BirdNET_v2.4_keras.zip/content', \
    'keras.zip'); \
z = zipfile.ZipFile('keras.zip'); \
z.extractall('/convert/keras_raw'); \
os.makedirs('/convert/keras', exist_ok=True); \
[shutil.copy2(os.path.join(r,f), '/convert/keras/'+f) \
 for r,_,fs in os.walk('/convert/keras_raw') \
 for f in fs \
 if not r.endswith('__MACOSX') and not f.startswith('._')]; \
os.remove('keras.zip'); \
shutil.rmtree('/convert/keras_raw')" && \
    ls -lh /convert/keras/

# Convert classifier sub-model to ONNX
RUN python3 convert_keras_to_onnx.py /convert/keras -o audio-model.onnx && \
    mv /convert/keras/audio-model.onnx /convert/audio-model.onnx && \
    ls -lh /convert/audio-model.onnx

# ── Runtime stage ──────────────────────────────────────────────────
# Minimal image: Rust binary + pre-converted ONNX model.
# No Python, no TensorFlow — all inference runs in native Rust.
FROM debian:trixie-slim

RUN apt-get update && apt-get install -y --no-install-recommends \
    libsqlite3-0 \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

COPY --from=builder /build/target/release/gaia-processing /usr/local/bin/gaia-processing

# Pre-converted BirdNET V2.4 classifier ONNX model (~49 MB).
# At runtime, ensure_onnx_file() copies this to the model directory
# if the manifest requests audio-model.onnx and it is absent.
COPY --from=converter /convert/audio-model.onnx /usr/local/share/gaia/models/audio-model.onnx

RUN mkdir -p /etc/gaia /data /models

# Default config — override by mounting your own
RUN echo '# Gaia Processing Server config\n\
LATITUDE=-1\n\
LONGITUDE=-1\n\
CONFIDENCE=0.7\n\
SENSITIVITY=1.25\n\
OVERLAP=0.0\n\
MODEL_DIR=/models\n\
DATABASE_LANG=en\n\
DB_PATH=/data/detections.db\n\
CAPTURE_SERVER_URL=http://capture:8089\n\
POLL_INTERVAL_SECS=5\n\
RECS_DIR=/data\n\
EXTRACTED=/data/Extracted\n' > /etc/gaia/gaia.conf

VOLUME ["/data", "/models"]

ENTRYPOINT ["gaia-processing"]
CMD ["/etc/gaia/gaia.conf"]
